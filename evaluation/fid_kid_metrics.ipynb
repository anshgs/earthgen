{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 22:07:17.905868: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 22:07:17.906845: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 22:07:17.914575: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 22:07:31.943279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchvision.transforms import transforms as T\n",
    "import torchvision\n",
    "from torch.multiprocessing import Pool, cpu_count\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "transform = T.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_file):\n",
    "    image = transform(Image.open(image_file))\n",
    "    ret_tensor = torch.zeros(49, 3, 512, 512)\n",
    "\n",
    "    for i in range(7):\n",
    "        current_row = i * 256\n",
    "        for j in range(7):\n",
    "            current_col = j * 256\n",
    "            \n",
    "            ret_tensor[i * 7 + j] = image[:, current_row:current_row + 512, current_col:current_col + 512]\n",
    "\n",
    "    return ret_tensor\n",
    "\n",
    "def get_fid_score_a(real_image_tensor, gen_image_tensor):\n",
    "    start_time = time.time()\n",
    "    real_image_tensor = real_image_tensor\n",
    "    gen_image_tensor = gen_image_tensor\n",
    "    fid = FrechetInceptionDistance(feature=2048, normalize=True)\n",
    "    fid.reset()\n",
    "    fid.update(real_image_tensor, real=True)\n",
    "    fid.update(gen_image_tensor, real=False)\n",
    "    fid_score = fid.compute()\n",
    "    print(f\"Time taken: {time.time() - start_time}\")\n",
    "    print(f\"FID score: {fid_score}\")\n",
    "    return fid_score\n",
    "\n",
    "def get_fid_score_b(real_image_tensor, gen_image_tensor):\n",
    "    N = len(real_image_tensor)\n",
    "    start_time = time.time()\n",
    "    real_image_tensor = real_image_tensor\n",
    "    gen_image_tensor = gen_image_tensor\n",
    "    fid = FrechetInceptionDistance(feature=2048, normalize=True)\n",
    "    fid.reset()\n",
    "\n",
    "    fid.update(real_image_tensor[:len(real_image_tensor) // 2], real=True)\n",
    "    fid.update(gen_image_tensor[len(gen_image_tensor) // 2:], real=False)\n",
    "    fid_score_1 = fid.compute()\n",
    "    print(f\"Time taken: {time.time() - start_time}\")\n",
    "    print(f\"FID score: {fid_score_1}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    fid.reset()\n",
    "\n",
    "    fid.update(real_image_tensor[len(real_image_tensor) // 2:], real=True)\n",
    "    fid.update(gen_image_tensor[:len(gen_image_tensor) // 2], real=False)\n",
    "    fid_score_2 = fid.compute()\n",
    "    print(f\"Time taken: {time.time() - start_time}\")\n",
    "    print(f\"FID score: {fid_score_2}\")\n",
    "\n",
    "    fid_score = (fid_score_1 + fid_score_2) / 2\n",
    "    print(f\"Final FID score: {fid_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasets_tiled(real_dir, fake_dir, num_images):\n",
    "    if os.listdir(real_dir) != os.listdir(fake_dir):\n",
    "        raise ValueError(\"The real and fake directories must contain the same number of images.\")\n",
    "\n",
    "    N = len(os.listdir(real_dir))\n",
    "    total_images = N * num_images\n",
    "\n",
    "    real_tensor = torch.zeros(total_images * 49, 3, 512, 512)\n",
    "    fake_tensor = torch.zeros(total_images * 49, 3, 512, 512)\n",
    "\n",
    "    folder_list = os.listdir(real_dir)\n",
    "\n",
    "    for i, folder_name in tqdm(enumerate(folder_list)):\n",
    "        real_folder_path = os.path.join(real_dir, folder_name)\n",
    "        fake_folder_path = os.path.join(fake_dir, folder_name)\n",
    "\n",
    "        real_images = os.listdir(real_folder_path)\n",
    "        fake_images = os.listdir(fake_folder_path)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            real_image_path = os.path.join(real_folder_path, real_images[j])\n",
    "            fake_image_path = os.path.join(fake_folder_path, fake_images[j])\n",
    "\n",
    "            real_tensor[(i * num_images + j) * 49 : ((i * num_images) + j + 1) * 49] = process_image(real_image_path)\n",
    "            fake_tensor[(i * num_images + j) * 49 : ((i * num_images) + j + 1) * 49] = process_image(fake_image_path)\n",
    "\n",
    "\n",
    "    return real_tensor, fake_tensor\n",
    "\n",
    "def process_datasets(real_dir, fake_dir, num_images):\n",
    "    if os.listdir(real_dir) != os.listdir(fake_dir):\n",
    "        raise ValueError(\"The real and fake directories must contain the same number of images.\")\n",
    "\n",
    "    N = len(os.listdir(real_dir))\n",
    "    total_images = N * num_images\n",
    "\n",
    "    real_tensor = torch.zeros(total_images, 3, 2048, 2048)\n",
    "    fake_tensor = torch.zeros(total_images, 3, 2048, 2048)\n",
    "\n",
    "    folder_list = os.listdir(real_dir)\n",
    "\n",
    "    for i, folder_name in tqdm(enumerate(folder_list)):\n",
    "        real_folder_path = os.path.join(real_dir, folder_name)\n",
    "        fake_folder_path = os.path.join(fake_dir, folder_name)\n",
    "\n",
    "        real_images = os.listdir(real_folder_path)\n",
    "        fake_images = os.listdir(fake_folder_path)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            real_image_path = os.path.join(real_folder_path, real_images[j])\n",
    "            fake_image_path = os.path.join(fake_folder_path, fake_images[j])\n",
    "\n",
    "            real_tensor[i * num_images + j] = transform(Image.open(real_image_path))\n",
    "            fake_tensor[i * num_images + j] = transform(Image.open(fake_image_path))\n",
    "\n",
    "    return real_tensor, fake_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = '/scratch/bbut/min_validation_set/bing_urban'\n",
    "fake = '/scratch/bbut/axiao/ours_validation_out2048_urban_from10_negative_52334'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image.kid import KernelInceptionDistance\n",
    "\n",
    "# Assuming process_image is defined as before\n",
    "def process_image_kid(image_path):\n",
    "    image = transform(Image.open(image_path))\n",
    "    return torch.unsqueeze(image, dim=0)\n",
    "\n",
    "# Function to process a single folder for real or fake images\n",
    "def process_folder(folder, real_or_fake):\n",
    "    # Define the base directory\n",
    "    base_dir = real if real_or_fake == 'real' else fake\n",
    "    # file_name = '20.png' if real_or_fake == 'real' else '10_gt_20.png'\n",
    "    file_name = '20.png' if os.path.exists(os.path.join(base_dir, folder, '20.png')) else '10_gt_20.png'\n",
    "    # Construct the path to the image\n",
    "    image_path = os.path.join(base_dir, folder, file_name)\n",
    "    # Process the image\n",
    "    if metric == 'fid':\n",
    "        tiles = process_image(image_path)\n",
    "    else:\n",
    "        tiles = process_image(image_path)\n",
    "    # Update the fid object with all tiles\n",
    "    for tile in tiles:\n",
    "        fid.update(tile.unsqueeze(0), real=(real_or_fake == 'real'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ansh/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "* kid score: (tensor(0.0549), tensor(0.0020))\t - 0\n",
      "* kid score: (tensor(0.0210), tensor(0.0013))\t - 52334\n",
      "* kid score: (tensor(0.0915), tensor(0.0018))\t - untuned_base\n",
      "* kid score: (tensor(0.3371), tensor(0.0039))\t - hat\n",
      "* kid score: (tensor(0.3857), tensor(0.0043))\t - liif\n",
      "* kid score: (tensor(0.2965), tensor(0.0038))\t - interpolation\n",
      "urban\n",
      "* kid score: (tensor(0.1474), tensor(0.0055))\t - 0\n",
      "* kid score: (tensor(0.0533), tensor(0.0026))\t - 52334\n",
      "* kid score: (tensor(0.1594), tensor(0.0034))\t - untuned_base\n",
      "* kid score: (tensor(0.4821), tensor(0.0062))\t - hat\n",
      "* kid score: (tensor(0.5249), tensor(0.0061))\t - liif\n",
      "* kid score: (tensor(0.4158), tensor(0.0052))\t - interpolation\n"
     ]
    }
   ],
   "source": [
    "for metric in ['kid', 'fid']:\n",
    "    for from_folder in ['20', 'urban']:\n",
    "        real = '/scratch/bbut/min_validation_set/bing_' + from_folder\n",
    "        if metric == 'fid':\n",
    "            fid = FrechetInceptionDistance(feature=2048, normalize=True, reset_real_features = False)\n",
    "        else:\n",
    "            fid = KernelInceptionDistance(feature=2048, normalize=True, reset_real_features = False)\n",
    "        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            # Create a progress bar\n",
    "            real_folders = list(os.listdir(real))            \n",
    "            # Submit tasks to the executor for real images\n",
    "            list(executor.map(process_folder, real_folders, ['real']*len(real_folders)))\n",
    "\n",
    "\n",
    "        # Setup the ThreadPoolExecutor\n",
    "        print(from_folder)\n",
    "\n",
    "        root = ''   #Add the common prefix of the fake images here (if any)\n",
    "        suffix = '' #Add the common suffix of the fake images here (if any)\n",
    "        \n",
    "        for fake_folder in ['0', '52334', 'untuned_base', 'hat', 'liif', 'interpolation']:\n",
    "            fake = root + fake_folder + suffix\n",
    "            fid.reset()\n",
    "            with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "                # Create a progress bar\n",
    "                fake_folders = list(os.listdir(fake))\n",
    "                # Submit tasks to the executor for fake images\n",
    "                list(executor.map(process_folder, fake_folders, ['fake']*len(fake_folders)))\n",
    "\n",
    "            # Compute the FID score\n",
    "            fid_score = fid.compute()\n",
    "            print(f\"* {metric} score: {fid_score}\\t - {fake_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthgen10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
